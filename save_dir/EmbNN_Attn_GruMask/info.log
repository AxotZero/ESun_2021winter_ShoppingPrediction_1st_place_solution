2021-11-17 13:05:13,787 - train - INFO - BigArch(
  (row_encoder): EmbedderNN(
    (embedder): EmbeddingGenerator(
      (embeddings): ModuleList(
        (0): Embedding(49, 14)
        (1): Embedding(4, 3)
        (2): Embedding(7, 5)
        (3): Embedding(30, 11)
        (4): Embedding(3, 3)
        (5): Embedding(12, 6)
        (6): Embedding(35, 12)
        (7): Embedding(3, 3)
        (8): Embedding(10, 6)
        (9): Embedding(2, 2)
      )
    )
    (nn): Sequential(
      (0): Linear(in_features=106, out_features=512, bias=True)
      (1): Dropout(p=0.3, inplace=False)
      (2): Linear(in_features=512, out_features=256, bias=True)
      (3): Dropout(p=0.3, inplace=False)
    )
  )
  (rows_aggregator): RowsTransformerAggregator(
    (AttenLayer): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (temporal_aggregator): TemporalGruAggregator(
    (gru): GRU(256, 512, batch_first=True, dropout=0.3)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=1024, bias=True)
    (1): Dropout(p=0.3, inplace=False)
    (2): Linear(in_features=1024, out_features=49, bias=True)
  )
)
Trainable parameters: 3261334
2021-11-17 13:06:20,138 - train - INFO - BigArch(
  (row_encoder): EmbedderNN(
    (embedder): EmbeddingGenerator(
      (embeddings): ModuleList(
        (0): Embedding(49, 14)
        (1): Embedding(4, 3)
        (2): Embedding(7, 5)
        (3): Embedding(30, 11)
        (4): Embedding(3, 3)
        (5): Embedding(12, 6)
        (6): Embedding(35, 12)
        (7): Embedding(3, 3)
        (8): Embedding(10, 6)
        (9): Embedding(2, 2)
      )
    )
    (nn): Sequential(
      (0): Linear(in_features=106, out_features=512, bias=True)
      (1): Dropout(p=0.3, inplace=False)
      (2): Linear(in_features=512, out_features=256, bias=True)
      (3): Dropout(p=0.3, inplace=False)
    )
  )
  (rows_aggregator): RowsTransformerAggregator(
    (AttenLayer): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (temporal_aggregator): TemporalGruAggregator(
    (gru): GRU(256, 512, batch_first=True, dropout=0.3)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=49, bias=True)
  )
)
Trainable parameters: 2710934
2021-11-17 13:11:11,507 - train - INFO - BigArch(
  (row_encoder): EmbedderNN(
    (embedder): EmbeddingGenerator(
      (embeddings): ModuleList(
        (0): Embedding(49, 14)
        (1): Embedding(4, 3)
        (2): Embedding(7, 5)
        (3): Embedding(30, 11)
        (4): Embedding(3, 3)
        (5): Embedding(12, 6)
        (6): Embedding(35, 12)
        (7): Embedding(3, 3)
        (8): Embedding(10, 6)
        (9): Embedding(2, 2)
      )
    )
    (nn): Sequential(
      (0): Linear(in_features=106, out_features=256, bias=True)
      (1): Dropout(p=0.3, inplace=False)
    )
  )
  (rows_aggregator): RowsTransformerAggregator(
    (AttenLayer): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (temporal_aggregator): TemporalGruAggregator(
    (gru): GRU(256, 512, batch_first=True, dropout=0.3)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=49, bias=True)
  )
)
Trainable parameters: 2552214
2021-11-17 13:13:43,228 - train - INFO - BigArch(
  (row_encoder): EmbedderNN(
    (embedder): EmbeddingGenerator(
      (embeddings): ModuleList(
        (0): Embedding(49, 14)
        (1): Embedding(4, 3)
        (2): Embedding(7, 5)
        (3): Embedding(30, 11)
        (4): Embedding(3, 3)
        (5): Embedding(12, 6)
        (6): Embedding(35, 12)
        (7): Embedding(3, 3)
        (8): Embedding(10, 6)
        (9): Embedding(2, 2)
      )
    )
    (nn): Sequential(
      (0): Linear(in_features=106, out_features=256, bias=True)
      (1): Dropout(p=0.3, inplace=False)
    )
  )
  (rows_aggregator): RowsTransformerAggregator(
    (AttenLayer): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (temporal_aggregator): TemporalGruAggregator(
    (gru): GRU(256, 512, batch_first=True, dropout=0.3)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=49, bias=True)
  )
)
Trainable parameters: 2552214
2021-11-17 13:15:23,700 - train - INFO - BigArch(
  (row_encoder): EmbedderNN(
    (embedder): EmbeddingGenerator(
      (embeddings): ModuleList(
        (0): Embedding(49, 14)
        (1): Embedding(4, 3)
        (2): Embedding(7, 5)
        (3): Embedding(30, 11)
        (4): Embedding(3, 3)
        (5): Embedding(12, 6)
        (6): Embedding(35, 12)
        (7): Embedding(3, 3)
        (8): Embedding(10, 6)
        (9): Embedding(2, 2)
      )
    )
    (nn): Sequential(
      (0): Linear(in_features=106, out_features=256, bias=True)
      (1): Dropout(p=0.3, inplace=False)
    )
  )
  (rows_aggregator): RowsTransformerAggregator(
    (AttenLayer): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (temporal_aggregator): TemporalGruAggregator(
    (gru): GRU(256, 512, batch_first=True, dropout=0.3)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=49, bias=True)
  )
)
Trainable parameters: 2552214
2021-11-17 13:28:44,989 - trainer - INFO -     epoch          : 1
2021-11-17 13:28:45,153 - trainer - INFO -     loss           : 2.834410328369636
2021-11-17 13:28:45,154 - trainer - INFO -     NDCG           : 0.4691641926765442
2021-11-17 13:28:45,154 - trainer - INFO -     NDCG16         : 0.5398549437522888
2021-11-17 13:28:45,154 - trainer - INFO -     val_loss       : 2.662367770578954
2021-11-17 13:28:45,154 - trainer - INFO -     val_NDCG       : 0.5039730072021484
2021-11-17 13:28:45,154 - trainer - INFO -     val_NDCG16     : 0.5631582736968994
2021-11-17 13:28:45,543 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-11-17 13:32:08,329 - train - INFO - BigArch(
  (row_encoder): EmbedderNN(
    (embedder): EmbeddingGenerator(
      (embeddings): ModuleList(
        (0): Embedding(49, 14)
        (1): Embedding(4, 3)
        (2): Embedding(7, 5)
        (3): Embedding(30, 11)
        (4): Embedding(3, 3)
        (5): Embedding(12, 6)
        (6): Embedding(35, 12)
        (7): Embedding(3, 3)
        (8): Embedding(10, 6)
        (9): Embedding(2, 2)
      )
    )
    (nn): Sequential(
      (0): Linear(in_features=106, out_features=256, bias=True)
      (1): Dropout(p=0.3, inplace=False)
    )
  )
  (rows_aggregator): RowsTransformerAggregator(
    (AttenLayer): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.3, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.3, inplace=False)
          (dropout2): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (temporal_aggregator): TemporalGruAggregator(
    (gru): GRU(256, 512, batch_first=True, dropout=0.3)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=49, bias=True)
  )
)
Trainable parameters: 2552214
2021-11-17 13:45:37,733 - trainer - INFO -     epoch          : 1
2021-11-17 13:45:37,859 - trainer - INFO -     loss           : 2.414851698550311
2021-11-17 13:45:37,859 - trainer - INFO -     NDCG           : 0.6021556258201599
2021-11-17 13:45:37,859 - trainer - INFO -     NDCG16         : 0.6657321453094482
2021-11-17 13:45:37,859 - trainer - INFO -     val_loss       : 2.2171743779987483
2021-11-17 13:45:37,859 - trainer - INFO -     val_NDCG       : 0.6612486839294434
2021-11-17 13:45:37,859 - trainer - INFO -     val_NDCG16     : 0.7146239280700684
2021-11-17 13:45:40,566 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-11-17 13:59:00,427 - trainer - INFO -     epoch          : 2
2021-11-17 13:59:00,530 - trainer - INFO -     loss           : 2.191334613964155
2021-11-17 13:59:00,531 - trainer - INFO -     NDCG           : 0.6656109690666199
2021-11-17 13:59:00,531 - trainer - INFO -     NDCG16         : 0.718999445438385
2021-11-17 13:59:00,531 - trainer - INFO -     val_loss       : 2.1567863696581355
2021-11-17 13:59:00,531 - trainer - INFO -     val_NDCG       : 0.6751343607902527
2021-11-17 13:59:00,531 - trainer - INFO -     val_NDCG16     : 0.728416383266449
2021-11-17 13:59:03,435 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-11-17 14:12:27,285 - trainer - INFO -     epoch          : 3
2021-11-17 14:12:27,302 - trainer - INFO -     loss           : 2.1616738584134487
2021-11-17 14:12:27,302 - trainer - INFO -     NDCG           : 0.6718171834945679
2021-11-17 14:12:27,302 - trainer - INFO -     NDCG16         : 0.7242799997329712
2021-11-17 14:12:27,303 - trainer - INFO -     val_loss       : 2.1378433249213478
2021-11-17 14:12:27,303 - trainer - INFO -     val_NDCG       : 0.679591178894043
2021-11-17 14:12:27,303 - trainer - INFO -     val_NDCG16     : 0.7328303456306458
2021-11-17 14:12:30,036 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-11-17 14:25:55,656 - trainer - INFO -     epoch          : 4
2021-11-17 14:25:55,788 - trainer - INFO -     loss           : 2.1465379377464195
2021-11-17 14:25:55,789 - trainer - INFO -     NDCG           : 0.6748605370521545
2021-11-17 14:25:55,789 - trainer - INFO -     NDCG16         : 0.7269635796546936
2021-11-17 14:25:55,789 - trainer - INFO -     val_loss       : 2.135819480016634
2021-11-17 14:25:55,789 - trainer - INFO -     val_NDCG       : 0.6772438883781433
2021-11-17 14:25:55,789 - trainer - INFO -     val_NDCG16     : 0.7316315174102783
2021-11-17 14:25:58,566 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-11-17 14:39:27,348 - trainer - INFO -     epoch          : 5
2021-11-17 14:39:27,475 - trainer - INFO -     loss           : 2.1353717349566423
2021-11-17 14:39:27,475 - trainer - INFO -     NDCG           : 0.6771323084831238
2021-11-17 14:39:27,475 - trainer - INFO -     NDCG16         : 0.7285376191139221
2021-11-17 14:39:27,476 - trainer - INFO -     val_loss       : 2.128897525118543
2021-11-17 14:39:27,476 - trainer - INFO -     val_NDCG       : 0.6799219846725464
2021-11-17 14:39:27,476 - trainer - INFO -     val_NDCG16     : 0.7324904799461365
2021-11-17 14:39:29,518 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-11-17 14:52:59,119 - trainer - INFO -     epoch          : 6
2021-11-17 14:52:59,269 - trainer - INFO -     loss           : 2.1272664383634345
2021-11-17 14:52:59,269 - trainer - INFO -     NDCG           : 0.6791343688964844
2021-11-17 14:52:59,270 - trainer - INFO -     NDCG16         : 0.7302121520042419
2021-11-17 14:52:59,270 - trainer - INFO -     val_loss       : 2.125734454315978
2021-11-17 14:52:59,270 - trainer - INFO -     val_NDCG       : 0.681475043296814
2021-11-17 14:52:59,270 - trainer - INFO -     val_NDCG16     : 0.7333347797393799
2021-11-17 14:53:01,820 - trainer - INFO - Improved! Saving current best: model_best.pth ...
