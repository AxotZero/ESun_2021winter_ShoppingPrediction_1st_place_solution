2021-12-21 01:50:10,558 - train - INFO - BigArch(
  (row_encoder): FixedEmbedderNN(
    (embedder): FixedEmbedder(
      (embeddings): ModuleList(
        (0): Embedding(49, 32)
        (1): Embedding(4, 32)
        (2): Embedding(7, 32)
        (3): Embedding(30, 32)
        (4): Embedding(3, 32)
        (5): Embedding(12, 32)
        (6): Embedding(35, 32)
        (7): Embedding(3, 32)
        (8): Embedding(10, 32)
        (9): Embedding(2, 32)
      )
      (nns): ModuleList(
        (0): Linear(in_features=1, out_features=32, bias=True)
        (1): Linear(in_features=1, out_features=32, bias=True)
        (2): Linear(in_features=1, out_features=32, bias=True)
        (3): Linear(in_features=1, out_features=32, bias=True)
        (4): Linear(in_features=1, out_features=32, bias=True)
        (5): Linear(in_features=1, out_features=32, bias=True)
        (6): Linear(in_features=1, out_features=32, bias=True)
        (7): Linear(in_features=1, out_features=32, bias=True)
        (8): Linear(in_features=1, out_features=32, bias=True)
        (9): Linear(in_features=1, out_features=32, bias=True)
        (10): Linear(in_features=1, out_features=32, bias=True)
        (11): Linear(in_features=1, out_features=32, bias=True)
        (12): Linear(in_features=1, out_features=32, bias=True)
        (13): Linear(in_features=1, out_features=32, bias=True)
        (14): Linear(in_features=1, out_features=32, bias=True)
        (15): Linear(in_features=1, out_features=32, bias=True)
        (16): Linear(in_features=1, out_features=32, bias=True)
        (17): Linear(in_features=1, out_features=32, bias=True)
        (18): Linear(in_features=1, out_features=32, bias=True)
        (19): Linear(in_features=1, out_features=32, bias=True)
        (20): Linear(in_features=1, out_features=32, bias=True)
        (21): Linear(in_features=1, out_features=32, bias=True)
        (22): Linear(in_features=1, out_features=32, bias=True)
        (23): Linear(in_features=1, out_features=32, bias=True)
        (24): Linear(in_features=1, out_features=32, bias=True)
        (25): Linear(in_features=1, out_features=32, bias=True)
        (26): Linear(in_features=1, out_features=32, bias=True)
        (27): Linear(in_features=1, out_features=32, bias=True)
        (28): Linear(in_features=1, out_features=32, bias=True)
        (29): Linear(in_features=1, out_features=32, bias=True)
        (30): Linear(in_features=1, out_features=32, bias=True)
        (31): Linear(in_features=1, out_features=32, bias=True)
        (32): Linear(in_features=1, out_features=32, bias=True)
        (33): Linear(in_features=1, out_features=32, bias=True)
        (34): Linear(in_features=1, out_features=32, bias=True)
        (35): Linear(in_features=1, out_features=32, bias=True)
        (36): Linear(in_features=1, out_features=32, bias=True)
        (37): Linear(in_features=1, out_features=32, bias=True)
        (38): Linear(in_features=1, out_features=32, bias=True)
        (39): Linear(in_features=1, out_features=32, bias=True)
        (40): Linear(in_features=1, out_features=32, bias=True)
        (41): Linear(in_features=1, out_features=32, bias=True)
      )
    )
    (input_layer): Linear(in_features=1664, out_features=128, bias=True)
    (nn_layers): Sequential(
      (0): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): Dropout(p=0.3, inplace=False)
        (2): Linear(in_features=256, out_features=128, bias=True)
        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (1): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): Dropout(p=0.3, inplace=False)
        (2): Linear(in_features=256, out_features=128, bias=True)
        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (2): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): Dropout(p=0.3, inplace=False)
        (2): Linear(in_features=256, out_features=128, bias=True)
        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_layer): Identity()
  )
  (rows_aggregator): RowsTransformerAggregator(
    (AttenLayer): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
          )
          (linear1): Linear(in_features=128, out_features=512, bias=True)
          (dropout): Dropout(p=0.3, inplace=False)
          (linear2): Linear(in_features=512, out_features=128, bias=True)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.3, inplace=False)
          (dropout2): Dropout(p=0.3, inplace=False)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
          )
          (linear1): Linear(in_features=128, out_features=512, bias=True)
          (dropout): Dropout(p=0.3, inplace=False)
          (linear2): Linear(in_features=512, out_features=128, bias=True)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.3, inplace=False)
          (dropout2): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (temporal_aggregator): Seq2SeqGruAggregator(
    (gru): GRU(128, 256, num_layers=2, batch_first=True, dropout=0.3)
  )
  (classifier): Sequential(
    (0): Linear(in_features=256, out_features=49, bias=True)
  )
)
Trainable parameters: 1519633
2021-12-21 05:29:13,078 - train - INFO - BigArch(
  (row_encoder): FixedEmbedderNN(
    (embedder): FixedEmbedder(
      (embeddings): ModuleList(
        (0): Embedding(49, 32)
        (1): Embedding(4, 32)
        (2): Embedding(7, 32)
        (3): Embedding(30, 32)
        (4): Embedding(3, 32)
        (5): Embedding(12, 32)
        (6): Embedding(35, 32)
        (7): Embedding(3, 32)
        (8): Embedding(10, 32)
        (9): Embedding(2, 32)
      )
      (nns): ModuleList(
        (0): Linear(in_features=1, out_features=32, bias=True)
        (1): Linear(in_features=1, out_features=32, bias=True)
        (2): Linear(in_features=1, out_features=32, bias=True)
        (3): Linear(in_features=1, out_features=32, bias=True)
        (4): Linear(in_features=1, out_features=32, bias=True)
        (5): Linear(in_features=1, out_features=32, bias=True)
        (6): Linear(in_features=1, out_features=32, bias=True)
        (7): Linear(in_features=1, out_features=32, bias=True)
        (8): Linear(in_features=1, out_features=32, bias=True)
        (9): Linear(in_features=1, out_features=32, bias=True)
        (10): Linear(in_features=1, out_features=32, bias=True)
        (11): Linear(in_features=1, out_features=32, bias=True)
        (12): Linear(in_features=1, out_features=32, bias=True)
        (13): Linear(in_features=1, out_features=32, bias=True)
        (14): Linear(in_features=1, out_features=32, bias=True)
        (15): Linear(in_features=1, out_features=32, bias=True)
        (16): Linear(in_features=1, out_features=32, bias=True)
        (17): Linear(in_features=1, out_features=32, bias=True)
        (18): Linear(in_features=1, out_features=32, bias=True)
        (19): Linear(in_features=1, out_features=32, bias=True)
        (20): Linear(in_features=1, out_features=32, bias=True)
        (21): Linear(in_features=1, out_features=32, bias=True)
        (22): Linear(in_features=1, out_features=32, bias=True)
        (23): Linear(in_features=1, out_features=32, bias=True)
        (24): Linear(in_features=1, out_features=32, bias=True)
        (25): Linear(in_features=1, out_features=32, bias=True)
        (26): Linear(in_features=1, out_features=32, bias=True)
        (27): Linear(in_features=1, out_features=32, bias=True)
        (28): Linear(in_features=1, out_features=32, bias=True)
        (29): Linear(in_features=1, out_features=32, bias=True)
        (30): Linear(in_features=1, out_features=32, bias=True)
        (31): Linear(in_features=1, out_features=32, bias=True)
        (32): Linear(in_features=1, out_features=32, bias=True)
        (33): Linear(in_features=1, out_features=32, bias=True)
        (34): Linear(in_features=1, out_features=32, bias=True)
        (35): Linear(in_features=1, out_features=32, bias=True)
        (36): Linear(in_features=1, out_features=32, bias=True)
        (37): Linear(in_features=1, out_features=32, bias=True)
        (38): Linear(in_features=1, out_features=32, bias=True)
        (39): Linear(in_features=1, out_features=32, bias=True)
        (40): Linear(in_features=1, out_features=32, bias=True)
        (41): Linear(in_features=1, out_features=32, bias=True)
      )
    )
    (input_layer): Linear(in_features=1664, out_features=128, bias=True)
    (nn_layers): Sequential(
      (0): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): Dropout(p=0.3, inplace=False)
        (2): Linear(in_features=256, out_features=128, bias=True)
        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (1): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): Dropout(p=0.3, inplace=False)
        (2): Linear(in_features=256, out_features=128, bias=True)
        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (2): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): Dropout(p=0.3, inplace=False)
        (2): Linear(in_features=256, out_features=128, bias=True)
        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_layer): Identity()
  )
  (rows_aggregator): RowsTransformerAggregator(
    (AttenLayer): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
          )
          (linear1): Linear(in_features=128, out_features=512, bias=True)
          (dropout): Dropout(p=0.3, inplace=False)
          (linear2): Linear(in_features=512, out_features=128, bias=True)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.3, inplace=False)
          (dropout2): Dropout(p=0.3, inplace=False)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
          )
          (linear1): Linear(in_features=128, out_features=512, bias=True)
          (dropout): Dropout(p=0.3, inplace=False)
          (linear2): Linear(in_features=512, out_features=128, bias=True)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.3, inplace=False)
          (dropout2): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (temporal_aggregator): Seq2SeqGruAggregator(
    (gru): GRU(128, 256, num_layers=2, batch_first=True, dropout=0.3)
  )
  (classifier): Sequential(
    (0): Linear(in_features=256, out_features=49, bias=True)
  )
)
Trainable parameters: 1519633
2021-12-22 03:18:29,993 - train - INFO - BigArch(
  (row_encoder): FixedEmbedderNN(
    (embedder): FixedEmbedder(
      (embeddings): ModuleList(
        (0): Embedding(49, 32)
        (1): Embedding(4, 32)
        (2): Embedding(7, 32)
        (3): Embedding(30, 32)
        (4): Embedding(3, 32)
        (5): Embedding(12, 32)
        (6): Embedding(35, 32)
        (7): Embedding(3, 32)
        (8): Embedding(10, 32)
        (9): Embedding(2, 32)
      )
      (nns): ModuleList(
        (0): Linear(in_features=1, out_features=32, bias=True)
        (1): Linear(in_features=1, out_features=32, bias=True)
        (2): Linear(in_features=1, out_features=32, bias=True)
        (3): Linear(in_features=1, out_features=32, bias=True)
        (4): Linear(in_features=1, out_features=32, bias=True)
        (5): Linear(in_features=1, out_features=32, bias=True)
        (6): Linear(in_features=1, out_features=32, bias=True)
        (7): Linear(in_features=1, out_features=32, bias=True)
        (8): Linear(in_features=1, out_features=32, bias=True)
        (9): Linear(in_features=1, out_features=32, bias=True)
        (10): Linear(in_features=1, out_features=32, bias=True)
        (11): Linear(in_features=1, out_features=32, bias=True)
        (12): Linear(in_features=1, out_features=32, bias=True)
        (13): Linear(in_features=1, out_features=32, bias=True)
        (14): Linear(in_features=1, out_features=32, bias=True)
        (15): Linear(in_features=1, out_features=32, bias=True)
        (16): Linear(in_features=1, out_features=32, bias=True)
        (17): Linear(in_features=1, out_features=32, bias=True)
        (18): Linear(in_features=1, out_features=32, bias=True)
        (19): Linear(in_features=1, out_features=32, bias=True)
        (20): Linear(in_features=1, out_features=32, bias=True)
        (21): Linear(in_features=1, out_features=32, bias=True)
        (22): Linear(in_features=1, out_features=32, bias=True)
        (23): Linear(in_features=1, out_features=32, bias=True)
        (24): Linear(in_features=1, out_features=32, bias=True)
        (25): Linear(in_features=1, out_features=32, bias=True)
        (26): Linear(in_features=1, out_features=32, bias=True)
        (27): Linear(in_features=1, out_features=32, bias=True)
        (28): Linear(in_features=1, out_features=32, bias=True)
        (29): Linear(in_features=1, out_features=32, bias=True)
        (30): Linear(in_features=1, out_features=32, bias=True)
        (31): Linear(in_features=1, out_features=32, bias=True)
        (32): Linear(in_features=1, out_features=32, bias=True)
        (33): Linear(in_features=1, out_features=32, bias=True)
        (34): Linear(in_features=1, out_features=32, bias=True)
        (35): Linear(in_features=1, out_features=32, bias=True)
        (36): Linear(in_features=1, out_features=32, bias=True)
        (37): Linear(in_features=1, out_features=32, bias=True)
        (38): Linear(in_features=1, out_features=32, bias=True)
        (39): Linear(in_features=1, out_features=32, bias=True)
        (40): Linear(in_features=1, out_features=32, bias=True)
        (41): Linear(in_features=1, out_features=32, bias=True)
      )
    )
    (input_layer): Linear(in_features=1664, out_features=128, bias=True)
    (nn_layers): Sequential(
      (0): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): Dropout(p=0.3, inplace=False)
        (2): Linear(in_features=256, out_features=128, bias=True)
        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (1): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): Dropout(p=0.3, inplace=False)
        (2): Linear(in_features=256, out_features=128, bias=True)
        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (2): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): Dropout(p=0.3, inplace=False)
        (2): Linear(in_features=256, out_features=128, bias=True)
        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_layer): Identity()
  )
  (rows_aggregator): RowsTransformerAggregator(
    (AttenLayer): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
          )
          (linear1): Linear(in_features=128, out_features=512, bias=True)
          (dropout): Dropout(p=0.3, inplace=False)
          (linear2): Linear(in_features=512, out_features=128, bias=True)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.3, inplace=False)
          (dropout2): Dropout(p=0.3, inplace=False)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
          )
          (linear1): Linear(in_features=128, out_features=512, bias=True)
          (dropout): Dropout(p=0.3, inplace=False)
          (linear2): Linear(in_features=512, out_features=128, bias=True)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.3, inplace=False)
          (dropout2): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (temporal_aggregator): Seq2SeqGruAggregator(
    (gru): GRU(128, 256, num_layers=2, batch_first=True, dropout=0.3)
  )
  (classifier): Sequential(
    (0): Linear(in_features=256, out_features=49, bias=True)
  )
)
Trainable parameters: 1519633
2021-12-22 03:34:30,822 - trainer - INFO -     epoch          : 1
2021-12-22 03:34:30,870 - trainer - INFO -     loss           : 2.6129276857723887
2021-12-22 03:34:30,870 - trainer - INFO -     seq2seq_NDCG   : 0.5547724962234497
2021-12-22 03:34:30,870 - trainer - INFO -     seq2seq_NDCG16 : 0.6203933358192444
2021-12-22 03:34:30,870 - trainer - INFO -     val_loss       : 2.3531900818085734
2021-12-22 03:34:30,870 - trainer - INFO -     val_seq2seq_NDCG: 0.643729031085968
2021-12-22 03:34:30,871 - trainer - INFO -     val_seq2seq_NDCG16: 0.7026565670967102
2021-12-22 03:34:31,010 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 03:49:39,500 - trainer - INFO -     epoch          : 2
2021-12-22 03:49:39,544 - trainer - INFO -     loss           : 2.331997024807042
2021-12-22 03:49:39,544 - trainer - INFO -     seq2seq_NDCG   : 0.6429029107093811
2021-12-22 03:49:39,544 - trainer - INFO -     seq2seq_NDCG16 : 0.7023107409477234
2021-12-22 03:49:39,544 - trainer - INFO -     val_loss       : 2.280613344343727
2021-12-22 03:49:39,544 - trainer - INFO -     val_seq2seq_NDCG: 0.6555172801017761
2021-12-22 03:49:39,544 - trainer - INFO -     val_seq2seq_NDCG16: 0.7151696085929871
2021-12-22 03:49:42,591 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 04:05:03,318 - trainer - INFO -     epoch          : 3
2021-12-22 04:05:09,587 - trainer - INFO -     loss           : 2.287961600151721
2021-12-22 04:05:09,587 - trainer - INFO -     seq2seq_NDCG   : 0.6507790684700012
2021-12-22 04:05:09,588 - trainer - INFO -     seq2seq_NDCG16 : 0.709464430809021
2021-12-22 04:05:09,588 - trainer - INFO -     val_loss       : 2.256944681372484
2021-12-22 04:05:09,588 - trainer - INFO -     val_seq2seq_NDCG: 0.6581222414970398
2021-12-22 04:05:09,588 - trainer - INFO -     val_seq2seq_NDCG16: 0.7175053954124451
2021-12-22 04:05:43,046 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 04:20:53,207 - trainer - INFO -     epoch          : 4
2021-12-22 04:20:54,718 - trainer - INFO -     loss           : 2.2688267259969974
2021-12-22 04:20:54,718 - trainer - INFO -     seq2seq_NDCG   : 0.6543097496032715
2021-12-22 04:20:54,718 - trainer - INFO -     seq2seq_NDCG16 : 0.712489664554596
2021-12-22 04:20:54,718 - trainer - INFO -     val_loss       : 2.243960610436052
2021-12-22 04:20:54,718 - trainer - INFO -     val_seq2seq_NDCG: 0.6612281799316406
2021-12-22 04:20:54,718 - trainer - INFO -     val_seq2seq_NDCG16: 0.7198072671890259
2021-12-22 04:21:22,756 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 04:36:24,675 - trainer - INFO -     epoch          : 5
2021-12-22 04:36:24,722 - trainer - INFO -     loss           : 2.258139041319766
2021-12-22 04:36:24,722 - trainer - INFO -     seq2seq_NDCG   : 0.6565970778465271
2021-12-22 04:36:24,722 - trainer - INFO -     seq2seq_NDCG16 : 0.7141644954681396
2021-12-22 04:36:24,722 - trainer - INFO -     val_loss       : 2.2387604493924114
2021-12-22 04:36:24,723 - trainer - INFO -     val_seq2seq_NDCG: 0.6626485586166382
2021-12-22 04:36:24,723 - trainer - INFO -     val_seq2seq_NDCG16: 0.7204755544662476
2021-12-22 04:36:27,816 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 04:51:30,331 - trainer - INFO -     epoch          : 6
2021-12-22 04:51:30,363 - trainer - INFO -     loss           : 2.25037664354267
2021-12-22 04:51:30,363 - trainer - INFO -     seq2seq_NDCG   : 0.6584308743476868
2021-12-22 04:51:30,363 - trainer - INFO -     seq2seq_NDCG16 : 0.7155370712280273
2021-12-22 04:51:30,363 - trainer - INFO -     val_loss       : 2.22954513410778
2021-12-22 04:51:30,363 - trainer - INFO -     val_seq2seq_NDCG: 0.6646615862846375
2021-12-22 04:51:30,363 - trainer - INFO -     val_seq2seq_NDCG16: 0.7219957709312439
2021-12-22 04:51:30,664 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 05:06:33,964 - trainer - INFO -     epoch          : 7
2021-12-22 05:06:33,994 - trainer - INFO -     loss           : 2.244854446412353
2021-12-22 05:06:33,994 - trainer - INFO -     seq2seq_NDCG   : 0.6598131656646729
2021-12-22 05:06:33,994 - trainer - INFO -     seq2seq_NDCG16 : 0.7163612842559814
2021-12-22 05:06:33,994 - trainer - INFO -     val_loss       : 2.226296322425003
2021-12-22 05:06:33,994 - trainer - INFO -     val_seq2seq_NDCG: 0.66526859998703
2021-12-22 05:06:33,994 - trainer - INFO -     val_seq2seq_NDCG16: 0.7219977974891663
2021-12-22 05:06:34,182 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 05:21:38,449 - trainer - INFO -     epoch          : 8
2021-12-22 05:21:38,489 - trainer - INFO -     loss           : 2.240513372177202
2021-12-22 05:21:38,490 - trainer - INFO -     seq2seq_NDCG   : 0.6610414385795593
2021-12-22 05:21:38,490 - trainer - INFO -     seq2seq_NDCG16 : 0.7170868515968323
2021-12-22 05:21:38,490 - trainer - INFO -     val_loss       : 2.222322865825175
2021-12-22 05:21:38,490 - trainer - INFO -     val_seq2seq_NDCG: 0.6669231653213501
2021-12-22 05:21:38,490 - trainer - INFO -     val_seq2seq_NDCG16: 0.7229978442192078
2021-12-22 05:21:38,724 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 05:36:39,877 - trainer - INFO -     epoch          : 9
2021-12-22 05:36:39,915 - trainer - INFO -     loss           : 2.237043541055876
2021-12-22 05:36:39,916 - trainer - INFO -     seq2seq_NDCG   : 0.6621748208999634
2021-12-22 05:36:39,916 - trainer - INFO -     seq2seq_NDCG16 : 0.7176146507263184
2021-12-22 05:36:39,916 - trainer - INFO -     val_loss       : 2.2213401660285035
2021-12-22 05:36:39,916 - trainer - INFO -     val_seq2seq_NDCG: 0.6670072674751282
2021-12-22 05:36:39,917 - trainer - INFO -     val_seq2seq_NDCG16: 0.7225954532623291
2021-12-22 05:36:40,175 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 05:51:46,272 - trainer - INFO -     epoch          : 10
2021-12-22 05:51:46,306 - trainer - INFO -     loss           : 2.234157713879703
2021-12-22 05:51:46,307 - trainer - INFO -     seq2seq_NDCG   : 0.6630244255065918
2021-12-22 05:51:46,307 - trainer - INFO -     seq2seq_NDCG16 : 0.7180595397949219
2021-12-22 05:51:46,307 - trainer - INFO -     val_loss       : 2.2182802818620297
2021-12-22 05:51:46,307 - trainer - INFO -     val_seq2seq_NDCG: 0.668484091758728
2021-12-22 05:51:46,307 - trainer - INFO -     val_seq2seq_NDCG16: 0.7234991788864136
2021-12-22 05:51:46,603 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 06:06:50,113 - trainer - INFO -     epoch          : 11
2021-12-22 06:06:50,148 - trainer - INFO -     loss           : 2.2319088764703205
2021-12-22 06:06:50,148 - trainer - INFO -     seq2seq_NDCG   : 0.6637461185455322
2021-12-22 06:06:50,148 - trainer - INFO -     seq2seq_NDCG16 : 0.7183792591094971
2021-12-22 06:06:50,148 - trainer - INFO -     val_loss       : 2.218498276322699
2021-12-22 06:06:50,148 - trainer - INFO -     val_seq2seq_NDCG: 0.6680906414985657
2021-12-22 06:06:50,148 - trainer - INFO -     val_seq2seq_NDCG16: 0.7229977250099182
2021-12-22 06:06:50,150 - trainer - INFO - Performance is lower than epoch: 10
2021-12-22 06:21:51,095 - trainer - INFO -     epoch          : 12
2021-12-22 06:21:51,152 - trainer - INFO -     loss           : 2.2299398375259174
2021-12-22 06:21:51,152 - trainer - INFO -     seq2seq_NDCG   : 0.6643921136856079
2021-12-22 06:21:51,152 - trainer - INFO -     seq2seq_NDCG16 : 0.7187122702598572
2021-12-22 06:21:51,152 - trainer - INFO -     val_loss       : 2.2143705324138825
2021-12-22 06:21:51,152 - trainer - INFO -     val_seq2seq_NDCG: 0.6693196892738342
2021-12-22 06:21:51,153 - trainer - INFO -     val_seq2seq_NDCG16: 0.7239064574241638
2021-12-22 06:21:51,547 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 06:36:52,898 - trainer - INFO -     epoch          : 13
2021-12-22 06:36:52,969 - trainer - INFO -     loss           : 2.2282362484581104
2021-12-22 06:36:52,969 - trainer - INFO -     seq2seq_NDCG   : 0.6648300886154175
2021-12-22 06:36:52,969 - trainer - INFO -     seq2seq_NDCG16 : 0.7189508676528931
2021-12-22 06:36:52,969 - trainer - INFO -     val_loss       : 2.2146321733284484
2021-12-22 06:36:52,969 - trainer - INFO -     val_seq2seq_NDCG: 0.6691635251045227
2021-12-22 06:36:52,970 - trainer - INFO -     val_seq2seq_NDCG16: 0.7235102653503418
2021-12-22 06:36:52,971 - trainer - INFO - Performance is lower than epoch: 12
2021-12-22 06:51:53,747 - trainer - INFO -     epoch          : 14
2021-12-22 06:51:53,843 - trainer - INFO -     loss           : 2.22686462957586
2021-12-22 06:51:53,844 - trainer - INFO -     seq2seq_NDCG   : 0.665215015411377
2021-12-22 06:51:53,844 - trainer - INFO -     seq2seq_NDCG16 : 0.7191386818885803
2021-12-22 06:51:53,844 - trainer - INFO -     val_loss       : 2.2129720300054916
2021-12-22 06:51:53,844 - trainer - INFO -     val_seq2seq_NDCG: 0.6699783802032471
2021-12-22 06:51:53,844 - trainer - INFO -     val_seq2seq_NDCG16: 0.7242514491081238
2021-12-22 06:51:54,356 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 07:06:55,256 - trainer - INFO -     epoch          : 15
2021-12-22 07:06:55,297 - trainer - INFO -     loss           : 2.2258470805882644
2021-12-22 07:06:55,297 - trainer - INFO -     seq2seq_NDCG   : 0.6655246019363403
2021-12-22 07:06:55,297 - trainer - INFO -     seq2seq_NDCG16 : 0.7193708419799805
2021-12-22 07:06:55,297 - trainer - INFO -     val_loss       : 2.2125745148914855
2021-12-22 07:06:55,297 - trainer - INFO -     val_seq2seq_NDCG: 0.6698737740516663
2021-12-22 07:06:55,298 - trainer - INFO -     val_seq2seq_NDCG16: 0.724050760269165
2021-12-22 07:06:55,513 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 07:21:51,197 - trainer - INFO -     epoch          : 16
2021-12-22 07:21:51,467 - trainer - INFO -     loss           : 2.2247775725195673
2021-12-22 07:21:51,468 - trainer - INFO -     seq2seq_NDCG   : 0.6658185720443726
2021-12-22 07:21:51,468 - trainer - INFO -     seq2seq_NDCG16 : 0.7194656133651733
2021-12-22 07:21:51,468 - trainer - INFO -     val_loss       : 2.210907364135508
2021-12-22 07:21:51,468 - trainer - INFO -     val_seq2seq_NDCG: 0.6704210042953491
2021-12-22 07:21:51,468 - trainer - INFO -     val_seq2seq_NDCG16: 0.724282443523407
2021-12-22 07:21:55,756 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 07:36:53,588 - trainer - INFO -     epoch          : 17
2021-12-22 07:36:53,817 - trainer - INFO -     loss           : 2.2236541428019887
2021-12-22 07:36:53,817 - trainer - INFO -     seq2seq_NDCG   : 0.6661932468414307
2021-12-22 07:36:53,817 - trainer - INFO -     seq2seq_NDCG16 : 0.7197084426879883
2021-12-22 07:36:53,817 - trainer - INFO -     val_loss       : 2.213837844331551
2021-12-22 07:36:53,817 - trainer - INFO -     val_seq2seq_NDCG: 0.6697821617126465
2021-12-22 07:36:53,818 - trainer - INFO -     val_seq2seq_NDCG16: 0.7237483859062195
2021-12-22 07:36:53,819 - trainer - INFO - Performance is lower than epoch: 16
2021-12-22 07:51:52,075 - trainer - INFO -     epoch          : 18
2021-12-22 07:51:52,222 - trainer - INFO -     loss           : 2.2228662931072507
2021-12-22 07:51:52,222 - trainer - INFO -     seq2seq_NDCG   : 0.6663388013839722
2021-12-22 07:51:52,222 - trainer - INFO -     seq2seq_NDCG16 : 0.7198025584220886
2021-12-22 07:51:52,222 - trainer - INFO -     val_loss       : 2.2100057656807666
2021-12-22 07:51:52,222 - trainer - INFO -     val_seq2seq_NDCG: 0.6708288192749023
2021-12-22 07:51:52,222 - trainer - INFO -     val_seq2seq_NDCG16: 0.7248035073280334
2021-12-22 07:51:52,627 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 08:06:45,554 - trainer - INFO -     epoch          : 19
2021-12-22 08:06:45,586 - trainer - INFO -     loss           : 2.222052280062372
2021-12-22 08:06:45,586 - trainer - INFO -     seq2seq_NDCG   : 0.6666327714920044
2021-12-22 08:06:45,586 - trainer - INFO -     seq2seq_NDCG16 : 0.719980776309967
2021-12-22 08:06:45,586 - trainer - INFO -     val_loss       : 2.210565973120882
2021-12-22 08:06:45,586 - trainer - INFO -     val_seq2seq_NDCG: 0.6699930429458618
2021-12-22 08:06:45,587 - trainer - INFO -     val_seq2seq_NDCG16: 0.7240035533905029
2021-12-22 08:06:45,588 - trainer - INFO - Performance is lower than epoch: 18
2021-12-22 08:21:45,399 - trainer - INFO -     epoch          : 20
2021-12-22 08:21:45,545 - trainer - INFO -     loss           : 2.2212028067156204
2021-12-22 08:21:45,545 - trainer - INFO -     seq2seq_NDCG   : 0.6668293476104736
2021-12-22 08:21:45,545 - trainer - INFO -     seq2seq_NDCG16 : 0.7200688719749451
2021-12-22 08:21:45,545 - trainer - INFO -     val_loss       : 2.208770001330949
2021-12-22 08:21:45,545 - trainer - INFO -     val_seq2seq_NDCG: 0.6710383892059326
2021-12-22 08:21:45,546 - trainer - INFO -     val_seq2seq_NDCG16: 0.7247388362884521
2021-12-22 08:21:46,118 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 08:36:45,360 - trainer - INFO -     epoch          : 21
2021-12-22 08:36:45,399 - trainer - INFO -     loss           : 2.2206731237666544
2021-12-22 08:36:45,399 - trainer - INFO -     seq2seq_NDCG   : 0.6670367121696472
2021-12-22 08:36:45,400 - trainer - INFO -     seq2seq_NDCG16 : 0.7201864123344421
2021-12-22 08:36:45,400 - trainer - INFO -     val_loss       : 2.2094928114615437
2021-12-22 08:36:45,400 - trainer - INFO -     val_seq2seq_NDCG: 0.6707193851470947
2021-12-22 08:36:45,400 - trainer - INFO -     val_seq2seq_NDCG16: 0.7243092060089111
2021-12-22 08:36:45,402 - trainer - INFO - Performance is lower than epoch: 20
2021-12-22 08:51:47,775 - trainer - INFO -     epoch          : 22
2021-12-22 08:51:47,808 - trainer - INFO -     loss           : 2.220086086429393
2021-12-22 08:51:47,808 - trainer - INFO -     seq2seq_NDCG   : 0.6670991778373718
2021-12-22 08:51:47,808 - trainer - INFO -     seq2seq_NDCG16 : 0.7202744483947754
2021-12-22 08:51:47,808 - trainer - INFO -     val_loss       : 2.2085134336710586
2021-12-22 08:51:47,808 - trainer - INFO -     val_seq2seq_NDCG: 0.6713436841964722
2021-12-22 08:51:47,809 - trainer - INFO -     val_seq2seq_NDCG16: 0.7248038053512573
2021-12-22 08:51:48,086 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 09:06:49,725 - trainer - INFO -     epoch          : 23
2021-12-22 09:06:49,772 - trainer - INFO -     loss           : 2.219617459381992
2021-12-22 09:06:49,772 - trainer - INFO -     seq2seq_NDCG   : 0.6673044562339783
2021-12-22 09:06:49,772 - trainer - INFO -     seq2seq_NDCG16 : 0.7204344868659973
2021-12-22 09:06:49,772 - trainer - INFO -     val_loss       : 2.208404124545319
2021-12-22 09:06:49,772 - trainer - INFO -     val_seq2seq_NDCG: 0.6709578037261963
2021-12-22 09:06:49,772 - trainer - INFO -     val_seq2seq_NDCG16: 0.7244678139686584
2021-12-22 09:06:50,101 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 09:21:49,304 - trainer - INFO -     epoch          : 24
2021-12-22 09:21:49,364 - trainer - INFO -     loss           : 2.2188252353241102
2021-12-22 09:21:49,364 - trainer - INFO -     seq2seq_NDCG   : 0.6674396395683289
2021-12-22 09:21:49,364 - trainer - INFO -     seq2seq_NDCG16 : 0.720488965511322
2021-12-22 09:21:49,364 - trainer - INFO -     val_loss       : 2.208113891084481
2021-12-22 09:21:49,364 - trainer - INFO -     val_seq2seq_NDCG: 0.6713952422142029
2021-12-22 09:21:49,365 - trainer - INFO -     val_seq2seq_NDCG16: 0.7247623205184937
2021-12-22 09:21:49,797 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 09:36:42,638 - trainer - INFO -     epoch          : 25
2021-12-22 09:36:42,684 - trainer - INFO -     loss           : 2.2184525397978603
2021-12-22 09:36:42,684 - trainer - INFO -     seq2seq_NDCG   : 0.6675785779953003
2021-12-22 09:36:42,684 - trainer - INFO -     seq2seq_NDCG16 : 0.7205235958099365
2021-12-22 09:36:42,684 - trainer - INFO -     val_loss       : 2.208622923287589
2021-12-22 09:36:42,684 - trainer - INFO -     val_seq2seq_NDCG: 0.6709336042404175
2021-12-22 09:36:42,684 - trainer - INFO -     val_seq2seq_NDCG16: 0.7245316505432129
2021-12-22 09:36:42,686 - trainer - INFO - Performance is lower than epoch: 24
2021-12-22 09:51:44,051 - trainer - INFO -     epoch          : 26
2021-12-22 09:51:44,090 - trainer - INFO -     loss           : 2.217977384840611
2021-12-22 09:51:44,090 - trainer - INFO -     seq2seq_NDCG   : 0.6676797866821289
2021-12-22 09:51:44,090 - trainer - INFO -     seq2seq_NDCG16 : 0.7206165194511414
2021-12-22 09:51:44,090 - trainer - INFO -     val_loss       : 2.2071644589114374
2021-12-22 09:51:44,090 - trainer - INFO -     val_seq2seq_NDCG: 0.6715090274810791
2021-12-22 09:51:44,090 - trainer - INFO -     val_seq2seq_NDCG16: 0.7248823642730713
2021-12-22 09:51:44,401 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 10:06:41,345 - trainer - INFO -     epoch          : 27
2021-12-22 10:06:41,380 - trainer - INFO -     loss           : 2.2175695711576395
2021-12-22 10:06:41,380 - trainer - INFO -     seq2seq_NDCG   : 0.6678448915481567
2021-12-22 10:06:41,380 - trainer - INFO -     seq2seq_NDCG16 : 0.720714271068573
2021-12-22 10:06:41,380 - trainer - INFO -     val_loss       : 2.2083571115723046
2021-12-22 10:06:41,380 - trainer - INFO -     val_seq2seq_NDCG: 0.6715337038040161
2021-12-22 10:06:41,380 - trainer - INFO -     val_seq2seq_NDCG16: 0.724878191947937
2021-12-22 10:06:41,382 - trainer - INFO - Performance is lower than epoch: 26
2021-12-22 10:21:27,942 - trainer - INFO -     epoch          : 28
2021-12-22 10:21:28,004 - trainer - INFO -     loss           : 2.2171036759325884
2021-12-22 10:21:28,004 - trainer - INFO -     seq2seq_NDCG   : 0.6679073572158813
2021-12-22 10:21:28,005 - trainer - INFO -     seq2seq_NDCG16 : 0.7207008600234985
2021-12-22 10:21:28,005 - trainer - INFO -     val_loss       : 2.2067080983115583
2021-12-22 10:21:28,005 - trainer - INFO -     val_seq2seq_NDCG: 0.6718628406524658
2021-12-22 10:21:28,005 - trainer - INFO -     val_seq2seq_NDCG16: 0.725189208984375
2021-12-22 10:21:28,292 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 10:36:25,261 - trainer - INFO -     epoch          : 29
2021-12-22 10:36:25,298 - trainer - INFO -     loss           : 2.2167454926691526
2021-12-22 10:36:25,298 - trainer - INFO -     seq2seq_NDCG   : 0.6679964661598206
2021-12-22 10:36:25,298 - trainer - INFO -     seq2seq_NDCG16 : 0.7208241820335388
2021-12-22 10:36:25,298 - trainer - INFO -     val_loss       : 2.2083650428010984
2021-12-22 10:36:25,298 - trainer - INFO -     val_seq2seq_NDCG: 0.6711397767066956
2021-12-22 10:36:25,299 - trainer - INFO -     val_seq2seq_NDCG16: 0.7247426509857178
2021-12-22 10:36:25,301 - trainer - INFO - Performance is lower than epoch: 28
2021-12-22 10:51:26,475 - trainer - INFO -     epoch          : 30
2021-12-22 10:51:26,521 - trainer - INFO -     loss           : 2.216302364816745
2021-12-22 10:51:26,521 - trainer - INFO -     seq2seq_NDCG   : 0.668133020401001
2021-12-22 10:51:26,522 - trainer - INFO -     seq2seq_NDCG16 : 0.720908522605896
2021-12-22 10:51:26,522 - trainer - INFO -     val_loss       : 2.2061765334185433
2021-12-22 10:51:26,522 - trainer - INFO -     val_seq2seq_NDCG: 0.6719058156013489
2021-12-22 10:51:26,522 - trainer - INFO -     val_seq2seq_NDCG16: 0.7250608801841736
2021-12-22 10:51:26,772 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 11:06:27,443 - trainer - INFO -     epoch          : 31
2021-12-22 11:06:27,539 - trainer - INFO -     loss           : 2.2159066413811055
2021-12-22 11:06:27,539 - trainer - INFO -     seq2seq_NDCG   : 0.6682090163230896
2021-12-22 11:06:27,539 - trainer - INFO -     seq2seq_NDCG16 : 0.7209935188293457
2021-12-22 11:06:27,539 - trainer - INFO -     val_loss       : 2.2072986410097086
2021-12-22 11:06:27,540 - trainer - INFO -     val_seq2seq_NDCG: 0.6714104413986206
2021-12-22 11:06:27,540 - trainer - INFO -     val_seq2seq_NDCG16: 0.724847137928009
2021-12-22 11:06:27,541 - trainer - INFO - Performance is lower than epoch: 30
2021-12-22 11:21:27,512 - trainer - INFO -     epoch          : 32
2021-12-22 11:21:27,566 - trainer - INFO -     loss           : 2.2156640060117287
2021-12-22 11:21:27,567 - trainer - INFO -     seq2seq_NDCG   : 0.6683019399642944
2021-12-22 11:21:27,567 - trainer - INFO -     seq2seq_NDCG16 : 0.7210038304328918
2021-12-22 11:21:27,567 - trainer - INFO -     val_loss       : 2.2056236401238403
2021-12-22 11:21:27,567 - trainer - INFO -     val_seq2seq_NDCG: 0.672036349773407
2021-12-22 11:21:27,567 - trainer - INFO -     val_seq2seq_NDCG16: 0.725048303604126
2021-12-22 11:21:27,878 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 11:36:30,131 - trainer - INFO -     epoch          : 33
2021-12-22 11:36:30,172 - trainer - INFO -     loss           : 2.215274295819088
2021-12-22 11:36:30,173 - trainer - INFO -     seq2seq_NDCG   : 0.668402910232544
2021-12-22 11:36:30,173 - trainer - INFO -     seq2seq_NDCG16 : 0.7210741639137268
2021-12-22 11:36:30,173 - trainer - INFO -     val_loss       : 2.2065246086901107
2021-12-22 11:36:30,173 - trainer - INFO -     val_seq2seq_NDCG: 0.6713687777519226
2021-12-22 11:36:30,173 - trainer - INFO -     val_seq2seq_NDCG16: 0.7245938181877136
2021-12-22 11:36:30,174 - trainer - INFO - Performance is lower than epoch: 32
2021-12-22 11:51:34,601 - trainer - INFO -     epoch          : 34
2021-12-22 11:51:34,641 - trainer - INFO -     loss           : 2.215053380336505
2021-12-22 11:51:34,641 - trainer - INFO -     seq2seq_NDCG   : 0.6684925556182861
2021-12-22 11:51:34,642 - trainer - INFO -     seq2seq_NDCG16 : 0.7211714386940002
2021-12-22 11:51:34,642 - trainer - INFO -     val_loss       : 2.2058699039547034
2021-12-22 11:51:34,642 - trainer - INFO -     val_seq2seq_NDCG: 0.6720126867294312
2021-12-22 11:51:34,642 - trainer - INFO -     val_seq2seq_NDCG16: 0.7252002954483032
2021-12-22 11:51:34,643 - trainer - INFO - Performance is lower than epoch: 32
2021-12-22 12:06:41,243 - trainer - INFO -     epoch          : 35
2021-12-22 12:06:41,306 - trainer - INFO -     loss           : 2.214581332295199
2021-12-22 12:06:41,306 - trainer - INFO -     seq2seq_NDCG   : 0.6685972213745117
2021-12-22 12:06:41,307 - trainer - INFO -     seq2seq_NDCG16 : 0.721186101436615
2021-12-22 12:06:41,307 - trainer - INFO -     val_loss       : 2.206331231100175
2021-12-22 12:06:41,307 - trainer - INFO -     val_seq2seq_NDCG: 0.6715040802955627
2021-12-22 12:06:41,307 - trainer - INFO -     val_seq2seq_NDCG16: 0.7248480319976807
2021-12-22 12:06:41,309 - trainer - INFO - Performance is lower than epoch: 32
2021-12-22 12:21:45,100 - trainer - INFO -     epoch          : 36
2021-12-22 12:21:45,161 - trainer - INFO -     loss           : 2.2145033344883838
2021-12-22 12:21:45,161 - trainer - INFO -     seq2seq_NDCG   : 0.6686314344406128
2021-12-22 12:21:45,161 - trainer - INFO -     seq2seq_NDCG16 : 0.7212404608726501
2021-12-22 12:21:45,161 - trainer - INFO -     val_loss       : 2.2052606219220956
2021-12-22 12:21:45,161 - trainer - INFO -     val_seq2seq_NDCG: 0.6719042062759399
2021-12-22 12:21:45,161 - trainer - INFO -     val_seq2seq_NDCG16: 0.72514808177948
2021-12-22 12:21:45,490 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 12:36:48,510 - trainer - INFO -     epoch          : 37
2021-12-22 12:36:48,565 - trainer - INFO -     loss           : 2.2140004517402088
2021-12-22 12:36:48,566 - trainer - INFO -     seq2seq_NDCG   : 0.6687537431716919
2021-12-22 12:36:48,566 - trainer - INFO -     seq2seq_NDCG16 : 0.7213413715362549
2021-12-22 12:36:48,566 - trainer - INFO -     val_loss       : 2.2063913863638174
2021-12-22 12:36:48,566 - trainer - INFO -     val_seq2seq_NDCG: 0.6718899011611938
2021-12-22 12:36:48,566 - trainer - INFO -     val_seq2seq_NDCG16: 0.7248802185058594
2021-12-22 12:36:48,568 - trainer - INFO - Performance is lower than epoch: 36
2021-12-22 12:51:49,585 - trainer - INFO -     epoch          : 38
2021-12-22 12:51:49,631 - trainer - INFO -     loss           : 2.2137704844361914
2021-12-22 12:51:49,632 - trainer - INFO -     seq2seq_NDCG   : 0.6687895655632019
2021-12-22 12:51:49,632 - trainer - INFO -     seq2seq_NDCG16 : 0.7213068604469299
2021-12-22 12:51:49,632 - trainer - INFO -     val_loss       : 2.205194545828778
2021-12-22 12:51:49,632 - trainer - INFO -     val_seq2seq_NDCG: 0.6721799969673157
2021-12-22 12:51:49,632 - trainer - INFO -     val_seq2seq_NDCG16: 0.7253143191337585
2021-12-22 12:51:49,966 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 13:06:51,060 - trainer - INFO -     epoch          : 39
2021-12-22 13:06:51,099 - trainer - INFO -     loss           : 2.213472099694699
2021-12-22 13:06:51,100 - trainer - INFO -     seq2seq_NDCG   : 0.6688541769981384
2021-12-22 13:06:51,100 - trainer - INFO -     seq2seq_NDCG16 : 0.7213202714920044
2021-12-22 13:06:51,100 - trainer - INFO -     val_loss       : 2.206276594830291
2021-12-22 13:06:51,101 - trainer - INFO -     val_seq2seq_NDCG: 0.6719271540641785
2021-12-22 13:06:51,101 - trainer - INFO -     val_seq2seq_NDCG16: 0.7250514626502991
2021-12-22 13:06:51,103 - trainer - INFO - Performance is lower than epoch: 38
2021-12-22 13:21:52,166 - trainer - INFO -     epoch          : 40
2021-12-22 13:21:52,209 - trainer - INFO -     loss           : 2.213190342933035
2021-12-22 13:21:52,210 - trainer - INFO -     seq2seq_NDCG   : 0.6689752340316772
2021-12-22 13:21:52,210 - trainer - INFO -     seq2seq_NDCG16 : 0.7213743329048157
2021-12-22 13:21:52,210 - trainer - INFO -     val_loss       : 2.205097497881526
2021-12-22 13:21:52,210 - trainer - INFO -     val_seq2seq_NDCG: 0.6722311973571777
2021-12-22 13:21:52,210 - trainer - INFO -     val_seq2seq_NDCG16: 0.725200891494751
2021-12-22 13:21:52,523 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 13:36:52,391 - trainer - INFO -     epoch          : 41
2021-12-22 13:36:52,427 - trainer - INFO -     loss           : 2.2129473771640145
2021-12-22 13:36:52,427 - trainer - INFO -     seq2seq_NDCG   : 0.6690603494644165
2021-12-22 13:36:52,427 - trainer - INFO -     seq2seq_NDCG16 : 0.7213991284370422
2021-12-22 13:36:52,427 - trainer - INFO -     val_loss       : 2.2052022782737946
2021-12-22 13:36:52,427 - trainer - INFO -     val_seq2seq_NDCG: 0.672089159488678
2021-12-22 13:36:52,427 - trainer - INFO -     val_seq2seq_NDCG16: 0.7250187993049622
2021-12-22 13:36:52,429 - trainer - INFO - Performance is lower than epoch: 40
2021-12-22 13:51:52,177 - trainer - INFO -     epoch          : 42
2021-12-22 13:51:52,223 - trainer - INFO -     loss           : 2.21262458342432
2021-12-22 13:51:52,223 - trainer - INFO -     seq2seq_NDCG   : 0.6691014170646667
2021-12-22 13:51:52,223 - trainer - INFO -     seq2seq_NDCG16 : 0.7214913964271545
2021-12-22 13:51:52,223 - trainer - INFO -     val_loss       : 2.2047436962956968
2021-12-22 13:51:52,223 - trainer - INFO -     val_seq2seq_NDCG: 0.6723759770393372
2021-12-22 13:51:52,224 - trainer - INFO -     val_seq2seq_NDCG16: 0.7252046465873718
2021-12-22 13:51:52,577 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 14:06:52,928 - trainer - INFO -     epoch          : 43
2021-12-22 14:06:53,141 - trainer - INFO -     loss           : 2.2123822293370026
2021-12-22 14:06:53,141 - trainer - INFO -     seq2seq_NDCG   : 0.6692153811454773
2021-12-22 14:06:53,141 - trainer - INFO -     seq2seq_NDCG16 : 0.7215498089790344
2021-12-22 14:06:53,141 - trainer - INFO -     val_loss       : 2.2053808165938045
2021-12-22 14:06:53,141 - trainer - INFO -     val_seq2seq_NDCG: 0.6718126535415649
2021-12-22 14:06:53,142 - trainer - INFO -     val_seq2seq_NDCG16: 0.7247360944747925
2021-12-22 14:06:53,144 - trainer - INFO - Performance is lower than epoch: 42
2021-12-22 14:21:47,206 - trainer - INFO -     epoch          : 44
2021-12-22 14:21:47,279 - trainer - INFO -     loss           : 2.2121695346429573
2021-12-22 14:21:47,279 - trainer - INFO -     seq2seq_NDCG   : 0.6692521572113037
2021-12-22 14:21:47,279 - trainer - INFO -     seq2seq_NDCG16 : 0.7215861082077026
2021-12-22 14:21:47,279 - trainer - INFO -     val_loss       : 2.2050524422579714
2021-12-22 14:21:47,279 - trainer - INFO -     val_seq2seq_NDCG: 0.6723405122756958
2021-12-22 14:21:47,279 - trainer - INFO -     val_seq2seq_NDCG16: 0.7252483367919922
2021-12-22 14:21:47,281 - trainer - INFO - Performance is lower than epoch: 42
2021-12-22 14:36:37,833 - trainer - INFO -     epoch          : 45
2021-12-22 14:36:37,873 - trainer - INFO -     loss           : 2.2119209992145774
2021-12-22 14:36:37,875 - trainer - INFO -     seq2seq_NDCG   : 0.6693400144577026
2021-12-22 14:36:37,875 - trainer - INFO -     seq2seq_NDCG16 : 0.7216212153434753
2021-12-22 14:36:37,875 - trainer - INFO -     val_loss       : 2.2054262917364955
2021-12-22 14:36:37,876 - trainer - INFO -     val_seq2seq_NDCG: 0.6720359325408936
2021-12-22 14:36:37,876 - trainer - INFO -     val_seq2seq_NDCG16: 0.7248641848564148
2021-12-22 14:36:37,877 - trainer - INFO - Performance is lower than epoch: 42
2021-12-22 14:51:27,931 - trainer - INFO -     epoch          : 46
2021-12-22 14:51:28,075 - trainer - INFO -     loss           : 2.2117513472349004
2021-12-22 14:51:28,076 - trainer - INFO -     seq2seq_NDCG   : 0.6693317294120789
2021-12-22 14:51:28,076 - trainer - INFO -     seq2seq_NDCG16 : 0.7216029167175293
2021-12-22 14:51:28,076 - trainer - INFO -     val_loss       : 2.2046070129365263
2021-12-22 14:51:28,076 - trainer - INFO -     val_seq2seq_NDCG: 0.6724736094474792
2021-12-22 14:51:28,076 - trainer - INFO -     val_seq2seq_NDCG16: 0.725292444229126
2021-12-22 14:51:28,880 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 15:06:24,046 - trainer - INFO -     epoch          : 47
2021-12-22 15:06:24,139 - trainer - INFO -     loss           : 2.2115715805414924
2021-12-22 15:06:24,140 - trainer - INFO -     seq2seq_NDCG   : 0.6694101691246033
2021-12-22 15:06:24,140 - trainer - INFO -     seq2seq_NDCG16 : 0.7216519713401794
2021-12-22 15:06:24,140 - trainer - INFO -     val_loss       : 2.205348771551381
2021-12-22 15:06:24,140 - trainer - INFO -     val_seq2seq_NDCG: 0.6721824407577515
2021-12-22 15:06:24,140 - trainer - INFO -     val_seq2seq_NDCG16: 0.7251044511795044
2021-12-22 15:06:24,141 - trainer - INFO - Performance is lower than epoch: 46
2021-12-22 15:21:10,393 - trainer - INFO -     epoch          : 48
2021-12-22 15:21:10,441 - trainer - INFO -     loss           : 2.211348683881363
2021-12-22 15:21:10,442 - trainer - INFO -     seq2seq_NDCG   : 0.6694310903549194
2021-12-22 15:21:10,442 - trainer - INFO -     seq2seq_NDCG16 : 0.721732497215271
2021-12-22 15:21:10,442 - trainer - INFO -     val_loss       : 2.2044516890250203
2021-12-22 15:21:10,442 - trainer - INFO -     val_seq2seq_NDCG: 0.6724916696548462
2021-12-22 15:21:10,442 - trainer - INFO -     val_seq2seq_NDCG16: 0.7254139184951782
2021-12-22 15:21:10,698 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 15:35:53,087 - trainer - INFO -     epoch          : 49
2021-12-22 15:35:53,137 - trainer - INFO -     loss           : 2.211018276306123
2021-12-22 15:35:53,137 - trainer - INFO -     seq2seq_NDCG   : 0.6695954203605652
2021-12-22 15:35:53,137 - trainer - INFO -     seq2seq_NDCG16 : 0.7218198180198669
2021-12-22 15:35:53,137 - trainer - INFO -     val_loss       : 2.2045652287085646
2021-12-22 15:35:53,137 - trainer - INFO -     val_seq2seq_NDCG: 0.6723460555076599
2021-12-22 15:35:53,138 - trainer - INFO -     val_seq2seq_NDCG16: 0.725162923336029
2021-12-22 15:35:53,140 - trainer - INFO - Performance is lower than epoch: 48
2021-12-22 15:50:47,800 - trainer - INFO -     epoch          : 50
2021-12-22 15:50:47,845 - trainer - INFO -     loss           : 2.2110555969745933
2021-12-22 15:50:47,845 - trainer - INFO -     seq2seq_NDCG   : 0.6695634722709656
2021-12-22 15:50:47,845 - trainer - INFO -     seq2seq_NDCG16 : 0.7217804193496704
2021-12-22 15:50:47,845 - trainer - INFO -     val_loss       : 2.2040107817296177
2021-12-22 15:50:47,845 - trainer - INFO -     val_seq2seq_NDCG: 0.6726299524307251
2021-12-22 15:50:47,845 - trainer - INFO -     val_seq2seq_NDCG16: 0.7254466414451599
2021-12-22 15:50:48,124 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 16:05:35,808 - trainer - INFO -     epoch          : 51
2021-12-22 16:05:35,945 - trainer - INFO -     loss           : 2.2106955104810795
2021-12-22 16:05:35,946 - trainer - INFO -     seq2seq_NDCG   : 0.6696742177009583
2021-12-22 16:05:35,946 - trainer - INFO -     seq2seq_NDCG16 : 0.7217695116996765
2021-12-22 16:05:35,946 - trainer - INFO -     val_loss       : 2.205375567116701
2021-12-22 16:05:35,946 - trainer - INFO -     val_seq2seq_NDCG: 0.6723287105560303
2021-12-22 16:05:35,946 - trainer - INFO -     val_seq2seq_NDCG16: 0.7250070571899414
2021-12-22 16:05:35,948 - trainer - INFO - Performance is lower than epoch: 50
2021-12-22 16:20:25,524 - trainer - INFO -     epoch          : 52
2021-12-22 16:20:25,613 - trainer - INFO -     loss           : 2.2105047020939628
2021-12-22 16:20:25,614 - trainer - INFO -     seq2seq_NDCG   : 0.6696742177009583
2021-12-22 16:20:25,614 - trainer - INFO -     seq2seq_NDCG16 : 0.7218337059020996
2021-12-22 16:20:25,614 - trainer - INFO -     val_loss       : 2.2040055060325683
2021-12-22 16:20:25,614 - trainer - INFO -     val_seq2seq_NDCG: 0.6726894378662109
2021-12-22 16:20:25,614 - trainer - INFO -     val_seq2seq_NDCG16: 0.7256019115447998
2021-12-22 16:20:25,945 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-22 16:35:09,868 - trainer - INFO -     epoch          : 53
2021-12-22 16:35:10,060 - trainer - INFO -     loss           : 2.2102597682657565
2021-12-22 16:35:10,061 - trainer - INFO -     seq2seq_NDCG   : 0.6697733998298645
2021-12-22 16:35:10,061 - trainer - INFO -     seq2seq_NDCG16 : 0.7219431400299072
2021-12-22 16:35:10,061 - trainer - INFO -     val_loss       : 2.20510497971264
2021-12-22 16:35:10,061 - trainer - INFO -     val_seq2seq_NDCG: 0.672451913356781
2021-12-22 16:35:10,061 - trainer - INFO -     val_seq2seq_NDCG16: 0.7253817319869995
2021-12-22 16:35:10,062 - trainer - INFO - Performance is lower than epoch: 52
2021-12-22 16:49:48,445 - trainer - INFO -     epoch          : 54
2021-12-22 16:49:48,498 - trainer - INFO -     loss           : 2.21011272700109
2021-12-22 16:49:48,499 - trainer - INFO -     seq2seq_NDCG   : 0.6698163747787476
2021-12-22 16:49:48,499 - trainer - INFO -     seq2seq_NDCG16 : 0.7219057083129883
2021-12-22 16:49:48,499 - trainer - INFO -     val_loss       : 2.204144541869688
2021-12-22 16:49:48,499 - trainer - INFO -     val_seq2seq_NDCG: 0.6727148294448853
2021-12-22 16:49:48,499 - trainer - INFO -     val_seq2seq_NDCG16: 0.7254502773284912
2021-12-22 16:49:48,501 - trainer - INFO - Performance is lower than epoch: 52
2021-12-22 17:04:39,303 - trainer - INFO -     epoch          : 55
2021-12-22 17:04:39,435 - trainer - INFO -     loss           : 2.210003205926008
2021-12-22 17:04:39,435 - trainer - INFO -     seq2seq_NDCG   : 0.6698010563850403
2021-12-22 17:04:39,435 - trainer - INFO -     seq2seq_NDCG16 : 0.7218837738037109
2021-12-22 17:04:39,435 - trainer - INFO -     val_loss       : 2.204248700300446
2021-12-22 17:04:39,435 - trainer - INFO -     val_seq2seq_NDCG: 0.6722912192344666
2021-12-22 17:04:39,435 - trainer - INFO -     val_seq2seq_NDCG16: 0.7250871062278748
2021-12-22 17:04:39,437 - trainer - INFO - Performance is lower than epoch: 52
2021-12-22 17:19:32,182 - trainer - INFO -     epoch          : 56
2021-12-22 17:19:32,298 - trainer - INFO -     loss           : 2.2098198400730515
2021-12-22 17:19:32,300 - trainer - INFO -     seq2seq_NDCG   : 0.669863760471344
2021-12-22 17:19:32,300 - trainer - INFO -     seq2seq_NDCG16 : 0.7219247817993164
2021-12-22 17:19:32,300 - trainer - INFO -     val_loss       : 2.2043743395744384
2021-12-22 17:19:32,301 - trainer - INFO -     val_seq2seq_NDCG: 0.672358512878418
2021-12-22 17:19:32,301 - trainer - INFO -     val_seq2seq_NDCG16: 0.7252641320228577
2021-12-22 17:19:32,301 - trainer - INFO - Validation performance didn't improve for 3 epochs. Training stops.
