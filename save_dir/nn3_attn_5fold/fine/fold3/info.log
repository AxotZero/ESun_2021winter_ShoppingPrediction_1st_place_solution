2021-12-21 05:31:20,580 - train - INFO - BigArch(
  (row_encoder): FixedEmbedderNN(
    (embedder): FixedEmbedder(
      (embeddings): ModuleList(
        (0): Embedding(49, 32)
        (1): Embedding(4, 32)
        (2): Embedding(7, 32)
        (3): Embedding(30, 32)
        (4): Embedding(3, 32)
        (5): Embedding(12, 32)
        (6): Embedding(35, 32)
        (7): Embedding(3, 32)
        (8): Embedding(10, 32)
        (9): Embedding(2, 32)
      )
      (nns): ModuleList(
        (0): Linear(in_features=1, out_features=32, bias=True)
        (1): Linear(in_features=1, out_features=32, bias=True)
        (2): Linear(in_features=1, out_features=32, bias=True)
        (3): Linear(in_features=1, out_features=32, bias=True)
        (4): Linear(in_features=1, out_features=32, bias=True)
        (5): Linear(in_features=1, out_features=32, bias=True)
        (6): Linear(in_features=1, out_features=32, bias=True)
        (7): Linear(in_features=1, out_features=32, bias=True)
        (8): Linear(in_features=1, out_features=32, bias=True)
        (9): Linear(in_features=1, out_features=32, bias=True)
        (10): Linear(in_features=1, out_features=32, bias=True)
        (11): Linear(in_features=1, out_features=32, bias=True)
        (12): Linear(in_features=1, out_features=32, bias=True)
        (13): Linear(in_features=1, out_features=32, bias=True)
        (14): Linear(in_features=1, out_features=32, bias=True)
        (15): Linear(in_features=1, out_features=32, bias=True)
        (16): Linear(in_features=1, out_features=32, bias=True)
        (17): Linear(in_features=1, out_features=32, bias=True)
        (18): Linear(in_features=1, out_features=32, bias=True)
        (19): Linear(in_features=1, out_features=32, bias=True)
        (20): Linear(in_features=1, out_features=32, bias=True)
        (21): Linear(in_features=1, out_features=32, bias=True)
        (22): Linear(in_features=1, out_features=32, bias=True)
        (23): Linear(in_features=1, out_features=32, bias=True)
        (24): Linear(in_features=1, out_features=32, bias=True)
        (25): Linear(in_features=1, out_features=32, bias=True)
        (26): Linear(in_features=1, out_features=32, bias=True)
        (27): Linear(in_features=1, out_features=32, bias=True)
        (28): Linear(in_features=1, out_features=32, bias=True)
        (29): Linear(in_features=1, out_features=32, bias=True)
        (30): Linear(in_features=1, out_features=32, bias=True)
        (31): Linear(in_features=1, out_features=32, bias=True)
        (32): Linear(in_features=1, out_features=32, bias=True)
        (33): Linear(in_features=1, out_features=32, bias=True)
        (34): Linear(in_features=1, out_features=32, bias=True)
        (35): Linear(in_features=1, out_features=32, bias=True)
        (36): Linear(in_features=1, out_features=32, bias=True)
        (37): Linear(in_features=1, out_features=32, bias=True)
        (38): Linear(in_features=1, out_features=32, bias=True)
        (39): Linear(in_features=1, out_features=32, bias=True)
        (40): Linear(in_features=1, out_features=32, bias=True)
        (41): Linear(in_features=1, out_features=32, bias=True)
      )
    )
    (input_layer): Linear(in_features=1664, out_features=128, bias=True)
    (nn_layers): Sequential(
      (0): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): Dropout(p=0.3, inplace=False)
        (2): Linear(in_features=256, out_features=128, bias=True)
        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (1): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): Dropout(p=0.3, inplace=False)
        (2): Linear(in_features=256, out_features=128, bias=True)
        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (2): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): Dropout(p=0.3, inplace=False)
        (2): Linear(in_features=256, out_features=128, bias=True)
        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_layer): Identity()
  )
  (rows_aggregator): RowsTransformerAggregator(
    (AttenLayer): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
          )
          (linear1): Linear(in_features=128, out_features=512, bias=True)
          (dropout): Dropout(p=0.3, inplace=False)
          (linear2): Linear(in_features=512, out_features=128, bias=True)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.3, inplace=False)
          (dropout2): Dropout(p=0.3, inplace=False)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
          )
          (linear1): Linear(in_features=128, out_features=512, bias=True)
          (dropout): Dropout(p=0.3, inplace=False)
          (linear2): Linear(in_features=512, out_features=128, bias=True)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.3, inplace=False)
          (dropout2): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (temporal_aggregator): Seq2SeqGruAggregator(
    (gru): GRU(128, 256, num_layers=2, batch_first=True, dropout=0.3)
  )
  (classifier): Sequential(
    (0): Linear(in_features=256, out_features=49, bias=True)
  )
)
Trainable parameters: 1519633
2021-12-21 05:32:16,311 - trainer - INFO - Loading checkpoint: ../save_dir/nn3_attn_5fold/base/fold3/model_best.pth ...
2021-12-23 05:28:38,100 - train - INFO - BigArch(
  (row_encoder): FixedEmbedderNN(
    (embedder): FixedEmbedder(
      (embeddings): ModuleList(
        (0): Embedding(49, 32)
        (1): Embedding(4, 32)
        (2): Embedding(7, 32)
        (3): Embedding(30, 32)
        (4): Embedding(3, 32)
        (5): Embedding(12, 32)
        (6): Embedding(35, 32)
        (7): Embedding(3, 32)
        (8): Embedding(10, 32)
        (9): Embedding(2, 32)
      )
      (nns): ModuleList(
        (0): Linear(in_features=1, out_features=32, bias=True)
        (1): Linear(in_features=1, out_features=32, bias=True)
        (2): Linear(in_features=1, out_features=32, bias=True)
        (3): Linear(in_features=1, out_features=32, bias=True)
        (4): Linear(in_features=1, out_features=32, bias=True)
        (5): Linear(in_features=1, out_features=32, bias=True)
        (6): Linear(in_features=1, out_features=32, bias=True)
        (7): Linear(in_features=1, out_features=32, bias=True)
        (8): Linear(in_features=1, out_features=32, bias=True)
        (9): Linear(in_features=1, out_features=32, bias=True)
        (10): Linear(in_features=1, out_features=32, bias=True)
        (11): Linear(in_features=1, out_features=32, bias=True)
        (12): Linear(in_features=1, out_features=32, bias=True)
        (13): Linear(in_features=1, out_features=32, bias=True)
        (14): Linear(in_features=1, out_features=32, bias=True)
        (15): Linear(in_features=1, out_features=32, bias=True)
        (16): Linear(in_features=1, out_features=32, bias=True)
        (17): Linear(in_features=1, out_features=32, bias=True)
        (18): Linear(in_features=1, out_features=32, bias=True)
        (19): Linear(in_features=1, out_features=32, bias=True)
        (20): Linear(in_features=1, out_features=32, bias=True)
        (21): Linear(in_features=1, out_features=32, bias=True)
        (22): Linear(in_features=1, out_features=32, bias=True)
        (23): Linear(in_features=1, out_features=32, bias=True)
        (24): Linear(in_features=1, out_features=32, bias=True)
        (25): Linear(in_features=1, out_features=32, bias=True)
        (26): Linear(in_features=1, out_features=32, bias=True)
        (27): Linear(in_features=1, out_features=32, bias=True)
        (28): Linear(in_features=1, out_features=32, bias=True)
        (29): Linear(in_features=1, out_features=32, bias=True)
        (30): Linear(in_features=1, out_features=32, bias=True)
        (31): Linear(in_features=1, out_features=32, bias=True)
        (32): Linear(in_features=1, out_features=32, bias=True)
        (33): Linear(in_features=1, out_features=32, bias=True)
        (34): Linear(in_features=1, out_features=32, bias=True)
        (35): Linear(in_features=1, out_features=32, bias=True)
        (36): Linear(in_features=1, out_features=32, bias=True)
        (37): Linear(in_features=1, out_features=32, bias=True)
        (38): Linear(in_features=1, out_features=32, bias=True)
        (39): Linear(in_features=1, out_features=32, bias=True)
        (40): Linear(in_features=1, out_features=32, bias=True)
        (41): Linear(in_features=1, out_features=32, bias=True)
      )
    )
    (input_layer): Linear(in_features=1664, out_features=128, bias=True)
    (nn_layers): Sequential(
      (0): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): Dropout(p=0.3, inplace=False)
        (2): Linear(in_features=256, out_features=128, bias=True)
        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (1): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): Dropout(p=0.3, inplace=False)
        (2): Linear(in_features=256, out_features=128, bias=True)
        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (2): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): Dropout(p=0.3, inplace=False)
        (2): Linear(in_features=256, out_features=128, bias=True)
        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_layer): Identity()
  )
  (rows_aggregator): RowsTransformerAggregator(
    (AttenLayer): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
          )
          (linear1): Linear(in_features=128, out_features=512, bias=True)
          (dropout): Dropout(p=0.3, inplace=False)
          (linear2): Linear(in_features=512, out_features=128, bias=True)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.3, inplace=False)
          (dropout2): Dropout(p=0.3, inplace=False)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
          )
          (linear1): Linear(in_features=128, out_features=512, bias=True)
          (dropout): Dropout(p=0.3, inplace=False)
          (linear2): Linear(in_features=512, out_features=128, bias=True)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.3, inplace=False)
          (dropout2): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (temporal_aggregator): Seq2SeqGruAggregator(
    (gru): GRU(128, 256, num_layers=2, batch_first=True, dropout=0.3)
  )
  (classifier): Sequential(
    (0): Linear(in_features=256, out_features=49, bias=True)
  )
)
Trainable parameters: 1519633
2021-12-23 05:29:29,188 - trainer - INFO - Loading checkpoint: ../save_dir/nn3_attn_5fold/base/fold3/model_best.pth ...
2021-12-23 05:29:34,308 - trainer - INFO - Checkpoint loaded. Resume training from epoch 33
2021-12-23 05:44:17,430 - trainer - INFO -     epoch          : 33
2021-12-23 05:44:17,534 - trainer - INFO -     loss           : 1.7299345363353356
2021-12-23 05:44:17,534 - trainer - INFO -     seq2seq_NDCG   : 0.6530360579490662
2021-12-23 05:44:17,534 - trainer - INFO -     seq2seq_NDCG16 : 0.722691535949707
2021-12-23 05:44:17,534 - trainer - INFO -     val_loss       : 1.7244733672617647
2021-12-23 05:44:17,534 - trainer - INFO -     val_seq2seq_NDCG: 0.6514937281608582
2021-12-23 05:44:17,535 - trainer - INFO -     val_seq2seq_NDCG16: 0.7248780131340027
2021-12-23 05:44:17,735 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-23 05:59:02,233 - trainer - INFO -     epoch          : 34
2021-12-23 05:59:02,408 - trainer - INFO -     loss           : 1.7285006282730737
2021-12-23 05:59:02,408 - trainer - INFO -     seq2seq_NDCG   : 0.6470930576324463
2021-12-23 05:59:02,409 - trainer - INFO -     seq2seq_NDCG16 : 0.7232764363288879
2021-12-23 05:59:02,409 - trainer - INFO -     val_loss       : 1.7229829929063998
2021-12-23 05:59:02,409 - trainer - INFO -     val_seq2seq_NDCG: 0.6487913131713867
2021-12-23 05:59:02,409 - trainer - INFO -     val_seq2seq_NDCG16: 0.7254164814949036
2021-12-23 05:59:03,279 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-23 06:13:52,742 - trainer - INFO -     epoch          : 35
2021-12-23 06:13:52,779 - trainer - INFO -     loss           : 1.7277288025034137
2021-12-23 06:13:52,779 - trainer - INFO -     seq2seq_NDCG   : 0.6445605158805847
2021-12-23 06:13:52,780 - trainer - INFO -     seq2seq_NDCG16 : 0.7235084176063538
2021-12-23 06:13:52,780 - trainer - INFO -     val_loss       : 1.723571203553768
2021-12-23 06:13:52,780 - trainer - INFO -     val_seq2seq_NDCG: 0.6464827060699463
2021-12-23 06:13:52,780 - trainer - INFO -     val_seq2seq_NDCG16: 0.7252300977706909
2021-12-23 06:13:52,797 - trainer - INFO - Performance is lower than epoch: 34
2021-12-23 06:28:41,952 - trainer - INFO -     epoch          : 36
2021-12-23 06:28:42,117 - trainer - INFO -     loss           : 1.7271120492571528
2021-12-23 06:28:42,117 - trainer - INFO -     seq2seq_NDCG   : 0.6434120535850525
2021-12-23 06:28:42,117 - trainer - INFO -     seq2seq_NDCG16 : 0.7236695289611816
2021-12-23 06:28:42,117 - trainer - INFO -     val_loss       : 1.7226533752573117
2021-12-23 06:28:42,118 - trainer - INFO -     val_seq2seq_NDCG: 0.6453937292098999
2021-12-23 06:28:42,118 - trainer - INFO -     val_seq2seq_NDCG16: 0.7256852388381958
2021-12-23 06:28:42,946 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-23 06:43:34,728 - trainer - INFO -     epoch          : 37
2021-12-23 06:43:34,814 - trainer - INFO -     loss           : 1.7266160283268681
2021-12-23 06:43:34,815 - trainer - INFO -     seq2seq_NDCG   : 0.6419191956520081
2021-12-23 06:43:34,815 - trainer - INFO -     seq2seq_NDCG16 : 0.7238740921020508
2021-12-23 06:43:34,815 - trainer - INFO -     val_loss       : 1.722778727636313
2021-12-23 06:43:34,815 - trainer - INFO -     val_seq2seq_NDCG: 0.6451712250709534
2021-12-23 06:43:34,815 - trainer - INFO -     val_seq2seq_NDCG16: 0.7254953980445862
2021-12-23 06:43:34,822 - trainer - INFO - Performance is lower than epoch: 36
2021-12-23 06:58:27,855 - trainer - INFO -     epoch          : 38
2021-12-23 06:58:27,980 - trainer - INFO -     loss           : 1.726082332989991
2021-12-23 06:58:27,980 - trainer - INFO -     seq2seq_NDCG   : 0.6410779356956482
2021-12-23 06:58:27,980 - trainer - INFO -     seq2seq_NDCG16 : 0.7240705490112305
2021-12-23 06:58:27,980 - trainer - INFO -     val_loss       : 1.7218965499297432
2021-12-23 06:58:27,980 - trainer - INFO -     val_seq2seq_NDCG: 0.6443102359771729
2021-12-23 06:58:27,981 - trainer - INFO -     val_seq2seq_NDCG16: 0.7259320020675659
2021-12-23 06:58:28,594 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-23 07:13:18,502 - trainer - INFO -     epoch          : 39
2021-12-23 07:13:18,710 - trainer - INFO -     loss           : 1.7256912958599098
2021-12-23 07:13:18,711 - trainer - INFO -     seq2seq_NDCG   : 0.6400492191314697
2021-12-23 07:13:18,711 - trainer - INFO -     seq2seq_NDCG16 : 0.7241839170455933
2021-12-23 07:13:18,711 - trainer - INFO -     val_loss       : 1.7221548962776008
2021-12-23 07:13:18,711 - trainer - INFO -     val_seq2seq_NDCG: 0.6431997418403625
2021-12-23 07:13:18,711 - trainer - INFO -     val_seq2seq_NDCG16: 0.7255082726478577
2021-12-23 07:13:18,720 - trainer - INFO - Performance is lower than epoch: 38
2021-12-23 07:28:09,177 - trainer - INFO -     epoch          : 40
2021-12-23 07:28:09,298 - trainer - INFO -     loss           : 1.725988682995831
2021-12-23 07:28:09,298 - trainer - INFO -     seq2seq_NDCG   : 0.6389250755310059
2021-12-23 07:28:09,298 - trainer - INFO -     seq2seq_NDCG16 : 0.7240443825721741
2021-12-23 07:28:09,299 - trainer - INFO -     val_loss       : 1.7218822493882435
2021-12-23 07:28:09,299 - trainer - INFO -     val_seq2seq_NDCG: 0.6430135369300842
2021-12-23 07:28:09,299 - trainer - INFO -     val_seq2seq_NDCG16: 0.7259502410888672
2021-12-23 07:28:10,310 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-23 07:43:16,373 - trainer - INFO -     epoch          : 41
2021-12-23 07:43:16,537 - trainer - INFO -     loss           : 1.7261608392095535
2021-12-23 07:43:16,537 - trainer - INFO -     seq2seq_NDCG   : 0.6358785033226013
2021-12-23 07:43:16,537 - trainer - INFO -     seq2seq_NDCG16 : 0.7240262031555176
2021-12-23 07:43:16,537 - trainer - INFO -     val_loss       : 1.721546290170811
2021-12-23 07:43:16,538 - trainer - INFO -     val_seq2seq_NDCG: 0.6401707530021667
2021-12-23 07:43:16,538 - trainer - INFO -     val_seq2seq_NDCG16: 0.7259536385536194
2021-12-23 07:43:17,434 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-23 07:58:24,487 - trainer - INFO -     epoch          : 42
2021-12-23 07:58:24,754 - trainer - INFO -     loss           : 1.7247285548495086
2021-12-23 07:58:24,754 - trainer - INFO -     seq2seq_NDCG   : 0.6364070177078247
2021-12-23 07:58:24,754 - trainer - INFO -     seq2seq_NDCG16 : 0.7245026230812073
2021-12-23 07:58:24,754 - trainer - INFO -     val_loss       : 1.7215031797013929
2021-12-23 07:58:24,754 - trainer - INFO -     val_seq2seq_NDCG: 0.6401635408401489
2021-12-23 07:58:24,754 - trainer - INFO -     val_seq2seq_NDCG16: 0.7260847687721252
2021-12-23 07:58:29,423 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-23 08:13:26,277 - trainer - INFO -     epoch          : 43
2021-12-23 08:13:26,324 - trainer - INFO -     loss           : 1.7244271080385625
2021-12-23 08:13:26,325 - trainer - INFO -     seq2seq_NDCG   : 0.6361925005912781
2021-12-23 08:13:26,325 - trainer - INFO -     seq2seq_NDCG16 : 0.7246012687683105
2021-12-23 08:13:26,325 - trainer - INFO -     val_loss       : 1.7219051253765136
2021-12-23 08:13:26,325 - trainer - INFO -     val_seq2seq_NDCG: 0.6411886215209961
2021-12-23 08:13:26,325 - trainer - INFO -     val_seq2seq_NDCG16: 0.7258929014205933
2021-12-23 08:13:26,327 - trainer - INFO - Performance is lower than epoch: 42
2021-12-23 08:28:25,060 - trainer - INFO -     epoch          : 44
2021-12-23 08:28:25,160 - trainer - INFO -     loss           : 1.724241051396268
2021-12-23 08:28:25,161 - trainer - INFO -     seq2seq_NDCG   : 0.6363562345504761
2021-12-23 08:28:25,161 - trainer - INFO -     seq2seq_NDCG16 : 0.7246333360671997
2021-12-23 08:28:25,161 - trainer - INFO -     val_loss       : 1.7212945872255603
2021-12-23 08:28:25,161 - trainer - INFO -     val_seq2seq_NDCG: 0.6406095623970032
2021-12-23 08:28:25,161 - trainer - INFO -     val_seq2seq_NDCG16: 0.7260899543762207
2021-12-23 08:28:26,264 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-23 08:43:25,156 - trainer - INFO -     epoch          : 45
2021-12-23 08:43:25,273 - trainer - INFO -     loss           : 1.723852552135099
2021-12-23 08:43:25,273 - trainer - INFO -     seq2seq_NDCG   : 0.6354207992553711
2021-12-23 08:43:25,273 - trainer - INFO -     seq2seq_NDCG16 : 0.7246763706207275
2021-12-23 08:43:25,273 - trainer - INFO -     val_loss       : 1.721646430852163
2021-12-23 08:43:25,273 - trainer - INFO -     val_seq2seq_NDCG: 0.6394410133361816
2021-12-23 08:43:25,273 - trainer - INFO -     val_seq2seq_NDCG16: 0.7258312702178955
2021-12-23 08:43:25,275 - trainer - INFO - Performance is lower than epoch: 44
2021-12-23 08:58:28,891 - trainer - INFO -     epoch          : 46
2021-12-23 08:58:29,337 - trainer - INFO -     loss           : 1.7236926791306422
2021-12-23 08:58:29,338 - trainer - INFO -     seq2seq_NDCG   : 0.6349451541900635
2021-12-23 08:58:29,338 - trainer - INFO -     seq2seq_NDCG16 : 0.7247797250747681
2021-12-23 08:58:29,338 - trainer - INFO -     val_loss       : 1.721103770958493
2021-12-23 08:58:29,338 - trainer - INFO -     val_seq2seq_NDCG: 0.6398605108261108
2021-12-23 08:58:29,338 - trainer - INFO -     val_seq2seq_NDCG16: 0.7261340618133545
2021-12-23 08:58:30,288 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-23 09:13:30,557 - trainer - INFO -     epoch          : 47
2021-12-23 09:13:30,642 - trainer - INFO -     loss           : 1.7233905138606378
2021-12-23 09:13:30,643 - trainer - INFO -     seq2seq_NDCG   : 0.6347332000732422
2021-12-23 09:13:30,643 - trainer - INFO -     seq2seq_NDCG16 : 0.7249074578285217
2021-12-23 09:13:30,643 - trainer - INFO -     val_loss       : 1.7210399552684306
2021-12-23 09:13:30,643 - trainer - INFO -     val_seq2seq_NDCG: 0.6388304829597473
2021-12-23 09:13:30,643 - trainer - INFO -     val_seq2seq_NDCG16: 0.726035475730896
2021-12-23 09:13:31,088 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-23 09:28:33,572 - trainer - INFO -     epoch          : 48
2021-12-23 09:28:33,743 - trainer - INFO -     loss           : 1.7230674725500192
2021-12-23 09:28:33,744 - trainer - INFO -     seq2seq_NDCG   : 0.6339102387428284
2021-12-23 09:28:33,744 - trainer - INFO -     seq2seq_NDCG16 : 0.7249177098274231
2021-12-23 09:28:33,744 - trainer - INFO -     val_loss       : 1.7211295497386963
2021-12-23 09:28:33,744 - trainer - INFO -     val_seq2seq_NDCG: 0.6375705599784851
2021-12-23 09:28:33,744 - trainer - INFO -     val_seq2seq_NDCG16: 0.725969135761261
2021-12-23 09:28:33,746 - trainer - INFO - Performance is lower than epoch: 47
2021-12-23 09:43:34,098 - trainer - INFO -     epoch          : 49
2021-12-23 09:43:34,205 - trainer - INFO -     loss           : 1.7228143008488992
2021-12-23 09:43:34,205 - trainer - INFO -     seq2seq_NDCG   : 0.6335386037826538
2021-12-23 09:43:34,205 - trainer - INFO -     seq2seq_NDCG16 : 0.7250581979751587
2021-12-23 09:43:34,205 - trainer - INFO -     val_loss       : 1.7213378708685756
2021-12-23 09:43:34,205 - trainer - INFO -     val_seq2seq_NDCG: 0.638133704662323
2021-12-23 09:43:34,205 - trainer - INFO -     val_seq2seq_NDCG16: 0.7259019613265991
2021-12-23 09:43:34,207 - trainer - INFO - Performance is lower than epoch: 47
2021-12-23 09:58:39,085 - trainer - INFO -     epoch          : 50
2021-12-23 09:58:39,206 - trainer - INFO -     loss           : 1.7225442718254476
2021-12-23 09:58:39,207 - trainer - INFO -     seq2seq_NDCG   : 0.6331734657287598
2021-12-23 09:58:39,207 - trainer - INFO -     seq2seq_NDCG16 : 0.7250857949256897
2021-12-23 09:58:39,207 - trainer - INFO -     val_loss       : 1.7209476546558273
2021-12-23 09:58:39,207 - trainer - INFO -     val_seq2seq_NDCG: 0.6376164555549622
2021-12-23 09:58:39,207 - trainer - INFO -     val_seq2seq_NDCG16: 0.7261468172073364
2021-12-23 09:58:39,959 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-23 10:13:37,836 - trainer - INFO -     epoch          : 51
2021-12-23 10:13:37,914 - trainer - INFO -     loss           : 1.722246767081897
2021-12-23 10:13:37,915 - trainer - INFO -     seq2seq_NDCG   : 0.6326713562011719
2021-12-23 10:13:37,915 - trainer - INFO -     seq2seq_NDCG16 : 0.7252718806266785
2021-12-23 10:13:37,915 - trainer - INFO -     val_loss       : 1.7212989622979518
2021-12-23 10:13:37,915 - trainer - INFO -     val_seq2seq_NDCG: 0.6362793445587158
2021-12-23 10:13:37,915 - trainer - INFO -     val_seq2seq_NDCG16: 0.7261521816253662
2021-12-23 10:13:37,916 - trainer - INFO - Performance is lower than epoch: 50
2021-12-23 10:28:35,409 - trainer - INFO -     epoch          : 52
2021-12-23 10:28:35,488 - trainer - INFO -     loss           : 1.7221363514413912
2021-12-23 10:28:35,488 - trainer - INFO -     seq2seq_NDCG   : 0.6321174502372742
2021-12-23 10:28:35,488 - trainer - INFO -     seq2seq_NDCG16 : 0.725238025188446
2021-12-23 10:28:35,488 - trainer - INFO -     val_loss       : 1.7210422537820724
2021-12-23 10:28:35,488 - trainer - INFO -     val_seq2seq_NDCG: 0.6364794969558716
2021-12-23 10:28:35,488 - trainer - INFO -     val_seq2seq_NDCG16: 0.7261438965797424
2021-12-23 10:28:35,490 - trainer - INFO - Performance is lower than epoch: 50
2021-12-23 10:43:35,755 - trainer - INFO -     epoch          : 53
2021-12-23 10:43:36,073 - trainer - INFO -     loss           : 1.7218767780565103
2021-12-23 10:43:36,074 - trainer - INFO -     seq2seq_NDCG   : 0.6317417025566101
2021-12-23 10:43:36,074 - trainer - INFO -     seq2seq_NDCG16 : 0.725337028503418
2021-12-23 10:43:36,074 - trainer - INFO -     val_loss       : 1.721818404429404
2021-12-23 10:43:36,075 - trainer - INFO -     val_seq2seq_NDCG: 0.6353943943977356
2021-12-23 10:43:36,075 - trainer - INFO -     val_seq2seq_NDCG16: 0.7259373664855957
2021-12-23 10:43:36,078 - trainer - INFO - Performance is lower than epoch: 50
2021-12-23 10:58:39,792 - trainer - INFO -     epoch          : 54
2021-12-23 10:58:39,977 - trainer - INFO -     loss           : 1.721622951810206
2021-12-23 10:58:39,977 - trainer - INFO -     seq2seq_NDCG   : 0.6312722563743591
2021-12-23 10:58:39,977 - trainer - INFO -     seq2seq_NDCG16 : 0.7254157066345215
2021-12-23 10:58:39,977 - trainer - INFO -     val_loss       : 1.7207544566420339
2021-12-23 10:58:39,978 - trainer - INFO -     val_seq2seq_NDCG: 0.6365911960601807
2021-12-23 10:58:39,978 - trainer - INFO -     val_seq2seq_NDCG16: 0.7262346744537354
2021-12-23 10:58:40,584 - trainer - INFO - Improved! Saving current best: model_best.pth ...
2021-12-23 11:13:41,161 - trainer - INFO -     epoch          : 55
2021-12-23 11:13:41,596 - trainer - INFO -     loss           : 1.7215376962703233
2021-12-23 11:13:41,599 - trainer - INFO -     seq2seq_NDCG   : 0.6308781504631042
2021-12-23 11:13:41,599 - trainer - INFO -     seq2seq_NDCG16 : 0.7253822684288025
2021-12-23 11:13:41,600 - trainer - INFO -     val_loss       : 1.7214678434459754
2021-12-23 11:13:41,600 - trainer - INFO -     val_seq2seq_NDCG: 0.6351109147071838
2021-12-23 11:13:41,600 - trainer - INFO -     val_seq2seq_NDCG16: 0.7260681390762329
2021-12-23 11:13:41,602 - trainer - INFO - Performance is lower than epoch: 54
2021-12-23 11:28:45,381 - trainer - INFO -     epoch          : 56
2021-12-23 11:28:45,475 - trainer - INFO -     loss           : 1.7212130723667693
2021-12-23 11:28:45,475 - trainer - INFO -     seq2seq_NDCG   : 0.6308649778366089
2021-12-23 11:28:45,475 - trainer - INFO -     seq2seq_NDCG16 : 0.7255271077156067
2021-12-23 11:28:45,475 - trainer - INFO -     val_loss       : 1.7212143987036117
2021-12-23 11:28:45,475 - trainer - INFO -     val_seq2seq_NDCG: 0.6345566511154175
2021-12-23 11:28:45,476 - trainer - INFO -     val_seq2seq_NDCG16: 0.7260512709617615
2021-12-23 11:28:45,477 - trainer - INFO - Performance is lower than epoch: 54
2021-12-23 11:43:48,667 - trainer - INFO -     epoch          : 57
2021-12-23 11:43:48,723 - trainer - INFO -     loss           : 1.7210388030291977
2021-12-23 11:43:48,723 - trainer - INFO -     seq2seq_NDCG   : 0.6299746036529541
2021-12-23 11:43:48,723 - trainer - INFO -     seq2seq_NDCG16 : 0.725584089756012
2021-12-23 11:43:48,724 - trainer - INFO -     val_loss       : 1.7215354570647334
2021-12-23 11:43:48,724 - trainer - INFO -     val_seq2seq_NDCG: 0.6342045068740845
2021-12-23 11:43:48,724 - trainer - INFO -     val_seq2seq_NDCG16: 0.7259199619293213
2021-12-23 11:43:48,725 - trainer - INFO - Performance is lower than epoch: 54
2021-12-23 11:58:57,537 - trainer - INFO -     epoch          : 58
2021-12-23 11:58:57,625 - trainer - INFO -     loss           : 1.7208258011214488
2021-12-23 11:58:57,626 - trainer - INFO -     seq2seq_NDCG   : 0.6297836899757385
2021-12-23 11:58:57,626 - trainer - INFO -     seq2seq_NDCG16 : 0.7255889773368835
2021-12-23 11:58:57,626 - trainer - INFO -     val_loss       : 1.7209341620545253
2021-12-23 11:58:57,627 - trainer - INFO -     val_seq2seq_NDCG: 0.6349676251411438
2021-12-23 11:58:57,627 - trainer - INFO -     val_seq2seq_NDCG16: 0.726302981376648
2021-12-23 11:58:57,627 - trainer - INFO - Validation performance didn't improve for 3 epochs. Training stops.
